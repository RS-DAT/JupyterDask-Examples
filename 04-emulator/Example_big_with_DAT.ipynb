{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b49214-0f60-433c-a4b3-35d323a85f5c",
   "metadata": {},
   "source": [
    "# Running Machine Learning tasks with DAT (Deployable Analysis environmenT) \n",
    "\n",
    "Problem at hand:\n",
    "Train a Machine Learning model on sparse data. Use the model to predict the target variables as map in space and time. \n",
    "\n",
    "![data](./figs/big.jpg)\n",
    "\n",
    "This notebook shows a simple workflow to:\n",
    "\n",
    "- train a RandomForest model \n",
    "- Preprocess data\n",
    "- Run the model \n",
    "\n",
    "This notebook and data are based on the research carried by Qianqian Han https://doi.org/10.5194/egusphere-egu24-5488.\n",
    "\n",
    "This notebook is available at https://github.com/RS-DAT/JupyterDask-Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8c7bc-f6f4-4270-8fae-018bbb6f5737",
   "metadata": {},
   "source": [
    "## Model training \n",
    "\n",
    "### Introducing `dask`, `dask-ml`, `MultiOutputRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f9a84-9521-4434-8ced-a2cc5680e2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import dcachefs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.preprocessing import OneHotEncoder\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f6ad2-cccb-476e-9d4a-320874ffc924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "from utils import training_testing_preprocess, igbp_to_landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d366193-564a-41e5-8ff6-b7adc39688c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_in_path = \"/scratch/EcoExtreML\"\n",
    "parent_out_path = \"/scratch/outputs/model\"\n",
    "os.makedirs(parent_out_path, exist_ok=True)\n",
    "              \n",
    "input_vars = ['Rin', 'Rli', 'p', 'Ta', 'ea', 'u', 'CO2', 'LAI','Vcmo', 'hc', 'Precip_msr','SSM', 'IGBP_veg_long', \n",
    "              'Rntot', 'LEtot', 'Htot','Gtot', 'Actot', 'SIF685', 'SIF740']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5f138-c906-411f-9bf7-723927eea951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "input_data = f\"dcache://pnfs/grid.sara.nl/data/remotesensing/disk/EcoExtreML/model/training_testing_2014.csv\"\n",
    "input_df = dd.read_csv(input_data, usecols=input_vars)\n",
    "\n",
    "# define one hot encoding for IGBP using dask-ml functions\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# preprocess data\n",
    "input_df = training_testing_preprocess(input_df)\n",
    "igbp_class = pd.read_csv(f\"{parent_in_path}/auxiliary/IGBP11unique.csv\")['0'].unique()\n",
    "input_df = igbp_to_landcover(input_df, encoder, igbp_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1109a-00ee-44c8-909c-d8503daf6512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training multiple outputs\n",
    "x_vars = ['Rin', 'Rli', 'p', 'Ta', 'ea', 'u', 'CO2', 'LAI','Vcmo', 'hc', 'Precip_msr','SSM', *[f'IGBP_veg_long{i}' for i in range(1, 12)]]\n",
    "x = input_df[x_vars]\n",
    "\n",
    "y_vars = ['LEtot','Htot','Rntot','Gtot', 'Actot','SIF685', 'SIF740']\n",
    "y = input_df[y_vars]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0, shuffle=True)\n",
    "\n",
    "regressor = MultiOutputRegressor(\n",
    "    RandomForestRegressor(n_estimators=10,\n",
    "                          max_depth=20,\n",
    "                          random_state=0,\n",
    "                          n_jobs=1,\n",
    "                          min_samples_split=10,\n",
    "                          min_samples_leaf=4),\n",
    "    n_jobs=7,\n",
    ")\n",
    "\n",
    "regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef045e8-d7e7-46aa-bae5-bc1343cb70b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# connect to the running Dask cluster\n",
    "from dask.distributed import Client\n",
    "client = Client(\"localhost:8786\")\n",
    "client.upload_file(\"utils.py\")  # upload utility module to workers\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848306bc-0654-437c-b54f-c3de9f1e4346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_values = x_train.compute()\n",
    "y_train_values = y_train.compute()\n",
    "\n",
    "# set joblib to use dask\n",
    "with joblib.parallel_backend('dask'):\n",
    "    regressor.fit(x_train_values, y_train_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd95db5-8f20-4db5-8f6c-fb160648243b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(regressor, f\"{parent_out_path}/model/model_multi.joblib\")\n",
    "print(\"model is saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08edf65-8296-44dc-9dae-66224c622d78",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "\n",
    "### Introducing `xr.open_mfdataset` and `xr.Dataset.to_zarr`\n",
    "\n",
    "#### skip running during the presentation\n",
    "\n",
    "This cell needs modifications with regards to I/O paths depending on the infra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72bae2-cff9-42c8-ab5e-6038c3e5ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dcachefs\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88976bdd-8244-4f81-89e9-0a0a1fb4effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "from utils import era5_preprocess, co2_preprocess, fix_coords, fix_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8dec8-cc71-4376-b844-1e8de8e64fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_in_path = f\"./data/global\"\n",
    "data_paths = {\"era5land\": f\"{parent_in_path}/era5land/*.nc\",\n",
    "            \"lai\": f\"{parent_in_path}/lai_v2/*.nc\",\n",
    "            \"ssm\": f\"{parent_in_path}/ssm/GlobalGSSM11km2014_20240214.tif\",\n",
    "            \"co2\": f\"{parent_in_path}/co2/CAMS_CO2_2003-2020.nc\",\n",
    "            \"landcover\": f\"{parent_in_path}/igbp/landcover10km_global.nc\",\n",
    "            \"vcmax\": f\"{parent_in_path}/vcmax/TROPOMI_Vmax_Tg_mean10km_global.nc\",\n",
    "            \"canopyheight\": f\"{parent_in_path}/canopy_height/canopy_height_11kmEurope20230921_10km.nc\",\n",
    "            }\n",
    "\n",
    "parent_out_path = \"somewhere/on/dcache\"\n",
    "\n",
    "# region of interest here EU\n",
    "bbox = [-31.28903052,  34.93055094,  68.93136141,  81.85192337]\n",
    "\n",
    "# time series\n",
    "start_time = \"2014-1-31\"\n",
    "end_time = \"2014-02-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de6f48-6b15-4273-9fb1-2d1bb3104746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_files(paths):\n",
    "    ofs = fsspec.open_files(paths, block_size=5*2**20)\n",
    "    return [of.open() for of in ofs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0e6f7-2bcb-4af6-8672-3a80fceb0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = 500\n",
    "\n",
    "co2_partial_func = partial(co2_preprocess, start_time=start_time, end_time=end_time)\n",
    "\n",
    "for data_path in data_paths:\n",
    "    ofs = open_files(data_paths[data_path])\n",
    "    # read data    \n",
    "    if data_path == \"era5land\":\n",
    "        ds = xr.open_mfdataset(ofs, engine=\"h5netcdf\")\n",
    "    \n",
    "    elif data_path == \"co2\":\n",
    "        ds = xr.open_mfdataset(ofs, engine=\"h5netcdf\", preprocess=co2_partial_func)\n",
    "        ds = ds.assign_coords(longitude=(((ds.longitude + 180) % 360) - 180))\n",
    "        \n",
    "    elif data_path == \"ssm\":  # this is a tif data\n",
    "        ds = rioxarray.open_rasterio(ofs[0])\n",
    "        ds = fix_coords(ds.to_dataset(name=\"ssm\"))       \n",
    "\n",
    "    else:\n",
    "        ds = xr.open_mfdataset(data_paths[data_path], preprocess=fix_coords)\n",
    "        \n",
    "    # convert day of year\n",
    "    ds = fix_time(ds, start_time)\n",
    "        \n",
    "    ds_sorted = ds.sortby(['longitude', 'latitude'])\n",
    "    masked_ds = ds_sorted.sel(longitude=slice(bbox[0], bbox[2]), latitude=slice(bbox[1], bbox[3]), time=slice(start_time, end_time))\n",
    "    \n",
    "    masked_ds = masked_ds.chunk(chunks=chunks)\n",
    "    \n",
    "    # save data to zarr\n",
    "    out_path = f\"{parent_out_path}/{data_path}_{start_time}_{end_time}_EU.zarr\"\n",
    "    fs_map = fsspec.get_mapper(out_path)\n",
    "    masked_ds.to_zarr(fs_map, mode='w')\n",
    "    print(f\"{out_path} is saved\")\n",
    "    print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936245cf-a125-4602-bc78-6fd5ca917af4",
   "metadata": {},
   "source": [
    "## Interpolations and Variable derivation\n",
    "#### Skip running during the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045e39b-1916-4e34-8bce-e08fdf0422d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "from PyStemmusScope import variable_conversion as vc\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from utils import interpolation, era5land_accumulated_vars, map_landcover_to_igbp, landcover_to_igbp\n",
    "from dask_ml.preprocessing import OneHotEncoder\n",
    "\n",
    "start_time = \"2014-1-31\"\n",
    "end_time = \"2014-02-10\"\n",
    "\n",
    "parent_in_path = \"./data\"\n",
    "data_paths = {\"era5land\": f\"{parent_in_path}/EU/era5land_{start_time}_{end_time}_EU.zarr\",\n",
    "              \"lai\": f\"{parent_in_path}/EU/lai_{start_time}_{end_time}_EU.zarr\",\n",
    "              \"ssm\": f\"{parent_in_path}/EU/ssm_{start_time}_{end_time}_EU.zarr\",\n",
    "              \"co2\": f\"{parent_in_path}/EU/co2_{start_time}_{end_time}_EU.zarr\",\n",
    "              \"landcover\": f\"{parent_in_path}/EU/landcover_{start_time}_{end_time}_EU.zarr\",\n",
    "              \"vcmax\": f\"{parent_in_path}/EU/vcmax_{start_time}_{end_time}_EU.zarr\",\n",
    "              \"canopyheight\": f\"{parent_in_path}/EU/canopyheight_{start_time}_{end_time}_EU.zarr\",\n",
    "              \"all_data\": f\"{parent_in_path}/EU/all_data_{start_time}_{end_time}_EU.zarr\",\n",
    "              \"igbp_table\": f\"{parent_in_path}/auxiliary/lccs_to_igbp_table.csv\",\n",
    "              \"igbp_class\": f\"{parent_in_path}/auxiliary/IGBP11unique.csv\",\n",
    "             }\n",
    "\n",
    "parent_out_path = \"/scratch/outputs/EU\"\n",
    "os.makedirs(parent_out_path, exist_ok=True)\n",
    "\n",
    "variable_names = {\"lai\": \"LAI\",\n",
    "                  \"ssm\": \"band_data\",\n",
    "                  \"co2\": \"co2\",\n",
    "                  \"canopyheight\": \"__xarray_dataarray_variable__\",\n",
    "                  \"vcmax\": \"__xarray_dataarray_variable__\",\n",
    "                  \"landcover\": \"lccs_class\"}  \n",
    "\n",
    "# interpolation\n",
    "era5land = xr.open_zarr(data_paths[\"era5land\"])\n",
    "other_coords = {\"time\": era5land.time, \"longitude\": era5land.longitude, \"latitude\": era5land.latitude}\n",
    "\n",
    "chunks = {\"time\": -1, \"longitude\": 500, \"latitude\": 500}\n",
    "for name in variable_names:\n",
    "    ds = xr.open_zarr(data_paths[name]).chunk(chunks)\n",
    "    ds_interpolated = interpolation(ds, other_coords)    \n",
    "    era5land[name] = ds_interpolated[variable_names[name]]\n",
    "\n",
    "era5land = era5land.chunk(chunks)\n",
    "\n",
    "# save to zarr\n",
    "out_path = f\"{parent_out_path}/all_data_{start_time}_{end_time}_EU.zarr\"\n",
    "encoding = {var: {'chunks': (era5land.sizes[\"time\"], 500, 500)} for var in era5land.data_vars}\n",
    "era5land.to_zarr(out_path, mode='w', encoding=encoding)\n",
    "print(f\"{out_path} is saved\")\n",
    "\n",
    "# variable derivation\n",
    "# read data\n",
    "chunks = {\"time\": 100, \"longitude\": 100, \"latitude\": 100}\n",
    "all_data = xr.open_zarr(data_paths[\"all_data\"])\n",
    "all_data = all_data.chunk(chunks)\n",
    "\n",
    "# variable calculations\n",
    "all_data = era5land_accumulated_vars(all_data, \"ssrd\", \"Rin\", 3600)\n",
    "all_data = era5land_accumulated_vars(all_data, \"strd\", \"Rli\", 3600)\n",
    "all_data = era5land_accumulated_vars(all_data, \"tp\", \"Precip_msr\", 0.001) # to mm\n",
    "all_data[\"p\"] = all_data[\"sp\"] / 100  # Pa -> hPa\n",
    "all_data[\"Ta\"] = all_data[\"t2m\"] - 273.15  # K -> degC\n",
    "all_data[\"ea\"] = vc.calculate_es(all_data[\"d2m\"] - 273.15)*10 # *10 is for kPa -> hPa\n",
    "all_data[\"u\"] = (all_data[\"u10\"] ** 2 + all_data[\"v10\"] ** 2) ** 0.5\n",
    "all_data[\"ssm\"] = all_data[\"ssm\"] / 1000\n",
    "\n",
    "# convert landcover to IGBP\n",
    "# lookup tables\n",
    "igbp_table = pd.read_csv(data_paths[\"igbp_table\"])\n",
    "igbp_class = pd.read_csv(data_paths[\"igbp_class\"])['0'].unique()\n",
    "\n",
    "# define one hot encoding for IGBP using dask-ml functions\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Unsorted categories are not yet supported by dask-ml\n",
    "igbp_stemmus_scope = np.sort(igbp_table[\"IGBP_STEMMUS_SCOPE\"].to_numpy().reshape(-1,1))\n",
    "encoder = encoder.fit(igbp_stemmus_scope)  \n",
    "lookup_table = igbp_table.set_index(\"lccs_class\").T.to_dict('records')[0]\n",
    "\n",
    "ds = landcover_to_igbp(all_data, \"landcover\", encoder, lookup_table, igbp_class)\n",
    "ds = ds.chunk(chunks)\n",
    "\n",
    "# rename some variables\n",
    "rename_vars = {\"co2\": \"CO2\", \"lai\": \"LAI\", \"canopyheight\": \"hc\", \"ssm\": \"SSM\", \"vcmax\": \"Vcmo\"}\n",
    "ds = ds.rename(rename_vars)\n",
    "\n",
    "# save to zarr\n",
    "out_path = f\"{parent_out_path}/model_input_{start_time}_{end_time}_EU.zarr\"\n",
    "encoding = {var: {'chunks': (50, 50, 50)} for var in ds.data_vars}\n",
    "ds.to_zarr(out_path, mode='w', encoding=encoding)\n",
    "print(f\"{out_path} is saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa8223-1b6f-40cd-b916-e73706929378",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Model prediction\n",
    "\n",
    "### Introducing `xr.map_blocks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecec875-bfb3-4872-b5d3-b1cafda150a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14cc0c-04bd-47fc-b39d-f0c516744132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "from utils import arr_to_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afcb372-7fca-43b9-b22a-2ed3e96b353e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = \"2014-1-31\"\n",
    "end_time = \"2014-02-10\"\n",
    "\n",
    "parent_in_path = \"/scratch/EcoExtreML\"\n",
    "parent_out_path = \"dcache://pnfs/grid.sara.nl/data/remotesensing/disk/EcoExtreML/out\"\n",
    "os.makedirs(parent_out_path, exist_ok=True)\n",
    "\n",
    "chunks = {\"time\": 100, \"longitude\": 200, \"latitude\": 200}\n",
    "\n",
    "model_input_file = f\"dcache://pnfs/grid.sara.nl/data/remotesensing/disk/EcoExtreML/EU/model_input_{start_time}_{end_time}_EU.zarr\"\n",
    "fs_map = fsspec.get_mapper(model_input_file, block_size=10*2**20)\n",
    "model_input = xr.open_zarr(fs_map)\n",
    "model_input = model_input.chunk(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce392f-fba4-42eb-8dd6-2a0376a2516a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "path_model = f\"{parent_in_path}/model/model_multi.joblib\"\n",
    "with open(path_model, 'rb') as f:\n",
    "    model = load(f)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b7f65-669e-441a-a67f-eb9619cd584c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_vars = [\n",
    "    'Rin', 'Rli', 'p', 'Ta', 'ea', 'u', 'CO2', 'LAI', 'Vcmo','hc', 'Precip_msr',  \n",
    "    'SSM',  *[f'IGBP_veg_long{i}' for i in range(1, 12)]\n",
    "]\n",
    "\n",
    "# select input/output data \n",
    "input_ds = model_input[input_vars]\n",
    "output_vars = ['LEtot','Htot','Rntot','Gtot', 'Actot','SIF685', 'SIF740']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2e44b-2cc0-4bda-91d9-49485f93ba76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predictFlux(input_ds, model, output_vars):\n",
    "\n",
    "    df_features = input_ds.to_dataframe().reset_index().drop(columns=[\"time\", \"longitude\", \"latitude\"])\n",
    "    \n",
    "    # Convert the nan value as 0 for the calculation\n",
    "    df_features = df_features.fillna(0)\n",
    "    \n",
    "    LEH = model.predict(df_features)\n",
    "    \n",
    "    output_ds = arr_to_ds(LEH, input_ds, output_vars)\n",
    "    return output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a94668-016c-4a68-8b92-bc3c53739e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define output template\n",
    "output_temp = xr.Dataset()\n",
    "ds_shape = (input_ds.sizes['time'], input_ds.sizes['latitude'], input_ds.sizes['longitude'])\n",
    "\n",
    "for var in output_vars:\n",
    "    output_temp[var] = xr.DataArray(\n",
    "        name = var,\n",
    "        data=da.zeros(ds_shape),\n",
    "        dims=input_ds.dims,\n",
    "        coords=input_ds.coords,\n",
    "    )\n",
    "output_temp = output_temp.chunk(chunks) # the same chunk as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559eab6b-7830-4b56-ae40-2156ebbafe13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result\n",
    "output_ds = xr.map_blocks(\n",
    "    predictFlux,\n",
    "    input_ds,\n",
    "    kwargs={\n",
    "        \"model\": model, \n",
    "        \"output_vars\": output_vars, \n",
    "    },\n",
    "    template=output_temp,\n",
    ")\n",
    "\n",
    "# save data\n",
    "out_path = f\"{parent_out_path}/predicted_{start_time}_{end_time}_EU.zarr\"\n",
    "fs_map = fsspec.get_mapper(out_path)\n",
    "output_ds.to_zarr(fs_map, mode='w')\n",
    "print(f\"{out_path} is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5587fa-5e8a-4178-8eab-0823cf7ad412",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ds = xr.open_zarr(fs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961e5db-83f0-4e32-9be0-3bedb39cfe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ds.LEtot.isel(time=2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ea721-4188-429f-a9f4-0e3c4e818040",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ds.Rntot.isel(time=2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa3589-3493-4cd9-aca0-a6c37ff27dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ds.LEtot.sel(latitude=(52.36),longitude=(4.90)).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
